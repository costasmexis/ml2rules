{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from xgboost import  XGBClassifier\n",
    "\n",
    "from ml2rules.machinelearning import *\n",
    "from ml2rules.rules import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataframe: (200000, 259)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../epfl_data.csv')\n",
    "print(f'Shape of the dataframe: {df.shape}')\n",
    "\n",
    "target = 'Stability'\n",
    "X = df.drop(target, axis=1)\n",
    "y = df[target].map({'s': 1, 'ns': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.40, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = XGBClassifier(random_state=SEED).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "[CV 1/3; 1/3] START booster=gblinear, colsample_bytree=0.6666666666666666, gamma=0.5994842503189408, learning_rate=0.021544346900318832, max_depth=10, min_child_weight=7, n_estimators=75, random_state=42, subsample=0.9444444444444444\n",
      "[CV 3/3; 1/3] START booster=gblinear, colsample_bytree=0.6666666666666666, gamma=0.5994842503189408, learning_rate=0.021544346900318832, max_depth=10, min_child_weight=7, n_estimators=75, random_state=42, subsample=0.9444444444444444\n",
      "[CV 2/3; 2/3] START booster=gbtree, colsample_bytree=0.9444444444444444, gamma=0.3593813663804626, learning_rate=0.01291549665014884, max_depth=10, min_child_weight=10, n_estimators=45, random_state=42, subsample=0.6111111111111112\n",
      "[CV 2/3; 1/3] START booster=gblinear, colsample_bytree=0.6666666666666666, gamma=0.5994842503189408, learning_rate=0.021544346900318832, max_depth=10, min_child_weight=7, n_estimators=75, random_state=42, subsample=0.9444444444444444\n",
      "[CV 1/3; 2/3] START booster=gbtree, colsample_bytree=0.9444444444444444, gamma=0.3593813663804626, learning_rate=0.01291549665014884, max_depth=10, min_child_weight=10, n_estimators=45, random_state=42, subsample=0.6111111111111112\n",
      "[CV 1/3; 3/3] START booster=dart, colsample_bytree=0.6666666666666666, gamma=0.1291549665014884, learning_rate=0.00774263682681127, max_depth=7, min_child_weight=3, n_estimators=75, random_state=42, subsample=0.5555555555555556\n",
      "[CV 3/3; 2/3] START booster=gbtree, colsample_bytree=0.9444444444444444, gamma=0.3593813663804626, learning_rate=0.01291549665014884, max_depth=10, min_child_weight=10, n_estimators=45, random_state=42, subsample=0.6111111111111112\n",
      "[CV 2/3; 3/3] START booster=dart, colsample_bytree=0.6666666666666666, gamma=0.1291549665014884, learning_rate=0.00774263682681127, max_depth=7, min_child_weight=3, n_estimators=75, random_state=42, subsample=0.5555555555555556\n",
      "[CV 3/3; 3/3] START booster=dart, colsample_bytree=0.6666666666666666, gamma=0.1291549665014884, learning_rate=0.00774263682681127, max_depth=7, min_child_weight=3, n_estimators=75, random_state=42, subsample=0.5555555555555556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/WUR/g0012069/env/main/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [17:51:40] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/WUR/g0012069/env/main/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [17:51:40] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/WUR/g0012069/env/main/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [17:51:40] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 1/3] END booster=gblinear, colsample_bytree=0.6666666666666666, gamma=0.5994842503189408, learning_rate=0.021544346900318832, max_depth=10, min_child_weight=7, n_estimators=75, random_state=42, subsample=0.9444444444444444;, score=0.365 total time=   3.8s\n",
      "[CV 1/3; 1/3] END booster=gblinear, colsample_bytree=0.6666666666666666, gamma=0.5994842503189408, learning_rate=0.021544346900318832, max_depth=10, min_child_weight=7, n_estimators=75, random_state=42, subsample=0.9444444444444444;, score=0.361 total time=   3.9s\n",
      "[CV 2/3; 1/3] END booster=gblinear, colsample_bytree=0.6666666666666666, gamma=0.5994842503189408, learning_rate=0.021544346900318832, max_depth=10, min_child_weight=7, n_estimators=75, random_state=42, subsample=0.9444444444444444;, score=0.359 total time=   4.8s\n",
      "[CV 2/3; 2/3] END booster=gbtree, colsample_bytree=0.9444444444444444, gamma=0.3593813663804626, learning_rate=0.01291549665014884, max_depth=10, min_child_weight=10, n_estimators=45, random_state=42, subsample=0.6111111111111112;, score=0.315 total time=   8.9s\n",
      "[CV 1/3; 2/3] END booster=gbtree, colsample_bytree=0.9444444444444444, gamma=0.3593813663804626, learning_rate=0.01291549665014884, max_depth=10, min_child_weight=10, n_estimators=45, random_state=42, subsample=0.6111111111111112;, score=0.313 total time=   8.9s\n",
      "[CV 3/3; 2/3] END booster=gbtree, colsample_bytree=0.9444444444444444, gamma=0.3593813663804626, learning_rate=0.01291549665014884, max_depth=10, min_child_weight=10, n_estimators=45, random_state=42, subsample=0.6111111111111112;, score=0.318 total time=   9.7s\n",
      "[CV 1/3; 3/3] END booster=dart, colsample_bytree=0.6666666666666666, gamma=0.1291549665014884, learning_rate=0.00774263682681127, max_depth=7, min_child_weight=3, n_estimators=75, random_state=42, subsample=0.5555555555555556;, score=0.293 total time= 1.4min\n",
      "[CV 3/3; 3/3] END booster=dart, colsample_bytree=0.6666666666666666, gamma=0.1291549665014884, learning_rate=0.00774263682681127, max_depth=7, min_child_weight=3, n_estimators=75, random_state=42, subsample=0.5555555555555556;, score=0.301 total time= 1.4min\n",
      "[CV 2/3; 3/3] END booster=dart, colsample_bytree=0.6666666666666666, gamma=0.1291549665014884, learning_rate=0.00774263682681127, max_depth=7, min_child_weight=3, n_estimators=75, random_state=42, subsample=0.5555555555555556;, score=0.299 total time= 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/WUR/g0012069/env/main/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [17:53:12] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/WUR/g0012069/env/main/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [17:53:13] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "m = XGBModel(X_train, X_test, y_train, y_test)\n",
    "m.train(n_iter=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib import rcParams\n",
    "# import tensorflow as tf\n",
    "\n",
    "# model = tf.keras.Sequential([\n",
    "#     tf.keras.layers.Dense(128, activation='relu'),\n",
    "#     tf.keras.layers.Dense(256, activation='relu'),\n",
    "#     tf.keras.layers.Dense(256, activation='relu'),\n",
    "#     tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "# ])\n",
    "# model.compile(\n",
    "#     loss=tf.keras.losses.binary_crossentropy,\n",
    "#     optimizer=tf.keras.optimizers.Adam(learning_rate=0.03),\n",
    "#     metrics=[\n",
    "#         tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "#         tf.keras.metrics.Precision(name='precision'),\n",
    "#         tf.keras.metrics.Recall(name='recall')\n",
    "#     ]\n",
    "# )\n",
    "# history = model.fit(X_train, y_train, epochs=100, batch_size=1028, validation_split=.3)\n",
    "\n",
    "# # Plot learning curve\n",
    "# plt.plot(history.history['accuracy'], label='accuracy')\n",
    "# plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "KernelExplainer.__init__() missing 1 required positional argument: 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshap\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m explainer \u001b[38;5;241m=\u001b[39m \u001b[43mshap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mKernelExplainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: KernelExplainer.__init__() missing 1 required positional argument: 'data'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
